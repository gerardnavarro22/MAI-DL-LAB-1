digraph {
	graph [size="15.45,15.45"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140297113504560 [label="
 (128, 29)" fillcolor=darkolivegreen1]
	140297113266416 [label=AddmmBackward0]
	140297113269152 -> 140297113266416
	140297113517600 [label="fc2.bias
 (29)" fillcolor=lightblue]
	140297113517600 -> 140297113269152
	140297113269152 [label=AccumulateGrad]
	140297113267712 -> 140297113266416
	140297113267712 [label=ReluBackward0]
	140297113259648 -> 140297113267712
	140297113259648 [label=MiopenBatchNormBackward0]
	140297113258448 -> 140297113259648
	140297113258448 [label=AddmmBackward0]
	140297113265600 -> 140297113258448
	140297113514640 [label="fc1.bias
 (512)" fillcolor=lightblue]
	140297113514640 -> 140297113265600
	140297113265600 [label=AccumulateGrad]
	140297113264256 -> 140297113258448
	140297113264256 [label=ViewBackward0]
	140297113260080 -> 140297113264256
	140297113260080 [label=NativeDropoutBackward0]
	140297113269920 -> 140297113260080
	140297113269920 [label=MaxPool2DWithIndicesBackward0]
	140297113267904 -> 140297113269920
	140297113267904 [label=ReluBackward0]
	140297113256192 -> 140297113267904
	140297113256192 [label=ConvolutionBackward0]
	140297113268336 -> 140297113256192
	140297113268336 [label=MaxPool2DWithIndicesBackward0]
	140297113259744 -> 140297113268336
	140297113259744 [label=ReluBackward0]
	140297113257104 -> 140297113259744
	140297113257104 [label=MiopenBatchNormBackward0]
	140297113268480 -> 140297113257104
	140297113268480 [label=ConvolutionBackward0]
	140297113268624 -> 140297113268480
	140297113268624 [label=MaxPool2DWithIndicesBackward0]
	140297113258016 -> 140297113268624
	140297113258016 [label=ReluBackward0]
	140297113264976 -> 140297113258016
	140297113264976 [label=MiopenBatchNormBackward0]
	140297113264880 -> 140297113264976
	140297113264880 [label=ConvolutionBackward0]
	140297113259504 -> 140297113264880
	140297303487360 [label="conv1.weight
 (32, 3, 5, 5)" fillcolor=lightblue]
	140297303487360 -> 140297113259504
	140297113259504 [label=AccumulateGrad]
	140297113257632 -> 140297113264880
	140297194760336 [label="conv1.bias
 (32)" fillcolor=lightblue]
	140297194760336 -> 140297113257632
	140297113257632 [label=AccumulateGrad]
	140297113257488 -> 140297113264976
	140297193023312 [label="batch_norm_conv_1.weight
 (32)" fillcolor=lightblue]
	140297193023312 -> 140297113257488
	140297113257488 [label=AccumulateGrad]
	140297113256960 -> 140297113264976
	140297295350656 [label="batch_norm_conv_1.bias
 (32)" fillcolor=lightblue]
	140297295350656 -> 140297113256960
	140297113256960 [label=AccumulateGrad]
	140297113258832 -> 140297113268480
	140297113202784 [label="conv2.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140297113202784 -> 140297113258832
	140297113258832 [label=AccumulateGrad]
	140297113271504 -> 140297113268480
	140297113203664 [label="conv2.bias
 (64)" fillcolor=lightblue]
	140297113203664 -> 140297113271504
	140297113271504 [label=AccumulateGrad]
	140297113261184 -> 140297113257104
	140297113203024 [label="batch_norm_conv_2.weight
 (64)" fillcolor=lightblue]
	140297113203024 -> 140297113261184
	140297113261184 [label=AccumulateGrad]
	140297113269200 -> 140297113257104
	140297113062272 [label="batch_norm_conv_2.bias
 (64)" fillcolor=lightblue]
	140297113062272 -> 140297113269200
	140297113269200 [label=AccumulateGrad]
	140297113266080 -> 140297113256192
	140297113062112 [label="conv3.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	140297113062112 -> 140297113266080
	140297113266080 [label=AccumulateGrad]
	140297113265120 -> 140297113256192
	140297113067312 [label="conv3.bias
 (128)" fillcolor=lightblue]
	140297113067312 -> 140297113265120
	140297113265120 [label=AccumulateGrad]
	140297113268576 -> 140297113258448
	140297113268576 [label=TBackward0]
	140297113266032 -> 140297113268576
	140297113511200 [label="fc1.weight
 (512, 131072)" fillcolor=lightblue]
	140297113511200 -> 140297113266032
	140297113266032 [label=AccumulateGrad]
	140297113259936 -> 140297113259648
	140297113517680 [label="batch_norm_fcnn.weight
 (512)" fillcolor=lightblue]
	140297113517680 -> 140297113259936
	140297113259936 [label=AccumulateGrad]
	140297113261712 -> 140297113259648
	140297113512880 [label="batch_norm_fcnn.bias
 (512)" fillcolor=lightblue]
	140297113512880 -> 140297113261712
	140297113261712 [label=AccumulateGrad]
	140297113256768 -> 140297113266416
	140297113256768 [label=TBackward0]
	140297113267232 -> 140297113256768
	140297113514080 [label="fc2.weight
 (29, 512)" fillcolor=lightblue]
	140297113514080 -> 140297113267232
	140297113267232 [label=AccumulateGrad]
	140297113266416 -> 140297113504560
}
