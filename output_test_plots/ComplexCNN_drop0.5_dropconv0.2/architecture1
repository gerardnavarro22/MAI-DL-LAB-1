digraph {
	graph [size="31.95,31.95"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	139655882988800 [label="
 (64, 29)" fillcolor=darkolivegreen1]
	139655882618384 [label=AddmmBackward0]
	139655882617856 -> 139655882618384
	139655883071440 [label="linear_layers.6.bias
 (29)" fillcolor=lightblue]
	139655883071440 -> 139655882617856
	139655882617856 [label=AccumulateGrad]
	139655882607008 -> 139655882618384
	139655882607008 [label=MulBackward0]
	139655882619104 -> 139655882607008
	139655882619104 [label=ReluBackward0]
	139655882616800 -> 139655882619104
	139655882616800 [label=AddmmBackward0]
	139655882617280 -> 139655882616800
	139655883067840 [label="linear_layers.3.bias
 (2048)" fillcolor=lightblue]
	139655883067840 -> 139655882617280
	139655882617280 [label=AccumulateGrad]
	139655882616512 -> 139655882616800
	139655882616512 [label=MulBackward0]
	139655882609600 -> 139655882616512
	139655882609600 [label=ReluBackward0]
	139655882616704 -> 139655882609600
	139655882616704 [label=AddmmBackward0]
	139655882618864 -> 139655882616704
	139655883076000 [label="linear_layers.0.bias
 (4096)" fillcolor=lightblue]
	139655883076000 -> 139655882618864
	139655882618864 [label=AccumulateGrad]
	139655882612960 -> 139655882616704
	139655882612960 [label=ViewBackward0]
	139655882610704 -> 139655882612960
	139655882610704 [label=MulBackward0]
	139655882616992 -> 139655882610704
	139655882616992 [label=MaxPool2DWithIndicesBackward0]
	139655882620112 -> 139655882616992
	139655882620112 [label=ReluBackward0]
	139655882620688 -> 139655882620112
	139655882620688 [label=MiopenBatchNormBackward0]
	139655882620016 -> 139655882620688
	139655882620016 [label=ConvolutionBackward0]
	139655882619872 -> 139655882620016
	139655882619872 [label=MaxPool2DWithIndicesBackward0]
	139655882614688 -> 139655882619872
	139655882614688 [label=ReluBackward0]
	139655882607968 -> 139655882614688
	139655882607968 [label=MiopenBatchNormBackward0]
	139655882617616 -> 139655882607968
	139655882617616 [label=ConvolutionBackward0]
	139655882616176 -> 139655882617616
	139655882616176 [label=ReluBackward0]
	139655882612720 -> 139655882616176
	139655882612720 [label=MiopenBatchNormBackward0]
	139655882618768 -> 139655882612720
	139655882618768 [label=ConvolutionBackward0]
	139655882612096 -> 139655882618768
	139655882612096 [label=MaxPool2DWithIndicesBackward0]
	139655882334432 -> 139655882612096
	139655882334432 [label=ReluBackward0]
	139655882328720 -> 139655882334432
	139655882328720 [label=MiopenBatchNormBackward0]
	139655882331840 -> 139655882328720
	139655882331840 [label=ConvolutionBackward0]
	139655882337168 -> 139655882331840
	139655882337168 [label=ReluBackward0]
	139655882337792 -> 139655882337168
	139655882337792 [label=MiopenBatchNormBackward0]
	139655882328048 -> 139655882337792
	139655882328048 [label=ConvolutionBackward0]
	139655882341440 -> 139655882328048
	139655882341440 [label=MaxPool2DWithIndicesBackward0]
	139655882338368 -> 139655882341440
	139655882338368 [label=ReluBackward0]
	139655882337120 -> 139655882338368
	139655882337120 [label=MiopenBatchNormBackward0]
	139655882334624 -> 139655882337120
	139655882334624 [label=ConvolutionBackward0]
	139655882328336 -> 139655882334624
	139655882328336 [label=MaxPool2DWithIndicesBackward0]
	139655882339040 -> 139655882328336
	139655882339040 [label=ReluBackward0]
	139655827766624 -> 139655882339040
	139655827766624 [label=MiopenBatchNormBackward0]
	139655827764848 -> 139655827766624
	139655827764848 [label=ConvolutionBackward0]
	139655827762400 -> 139655827764848
	139655962104016 [label="conv_layers.0.weight
 (64, 3, 3, 3)" fillcolor=lightblue]
	139655962104016 -> 139655827762400
	139655827762400 [label=AccumulateGrad]
	139655827761296 -> 139655827764848
	139656055655056 [label="conv_layers.0.bias
 (64)" fillcolor=lightblue]
	139656055655056 -> 139655827761296
	139655827761296 [label=AccumulateGrad]
	139655827764800 -> 139655827766624
	139655889090928 [label="conv_layers.1.weight
 (64)" fillcolor=lightblue]
	139655889090928 -> 139655827764800
	139655827764800 [label=AccumulateGrad]
	139655827767056 -> 139655827766624
	139655889090848 [label="conv_layers.1.bias
 (64)" fillcolor=lightblue]
	139655889090848 -> 139655827767056
	139655827767056 [label=AccumulateGrad]
	139655882338608 -> 139655882334624
	139655882373168 [label="conv_layers.4.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	139655882373168 -> 139655882338608
	139655882338608 [label=AccumulateGrad]
	139655882333904 -> 139655882334624
	139655882373968 [label="conv_layers.4.bias
 (128)" fillcolor=lightblue]
	139655882373968 -> 139655882333904
	139655882333904 [label=AccumulateGrad]
	139655882334720 -> 139655882337120
	139655882360208 [label="conv_layers.5.weight
 (128)" fillcolor=lightblue]
	139655882360208 -> 139655882334720
	139655882334720 [label=AccumulateGrad]
	139655882335824 -> 139655882337120
	139655882373488 [label="conv_layers.5.bias
 (128)" fillcolor=lightblue]
	139655882373488 -> 139655882335824
	139655882335824 [label=AccumulateGrad]
	139655882329728 -> 139655882328048
	139655883066720 [label="conv_layers.8.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	139655883066720 -> 139655882329728
	139655882329728 [label=AccumulateGrad]
	139655882326752 -> 139655882328048
	139655883066160 [label="conv_layers.8.bias
 (256)" fillcolor=lightblue]
	139655883066160 -> 139655882326752
	139655882326752 [label=AccumulateGrad]
	139655882328096 -> 139655882337792
	139655883064480 [label="conv_layers.9.weight
 (256)" fillcolor=lightblue]
	139655883064480 -> 139655882328096
	139655882328096 [label=AccumulateGrad]
	139655882340576 -> 139655882337792
	139655883063760 [label="conv_layers.9.bias
 (256)" fillcolor=lightblue]
	139655883063760 -> 139655882340576
	139655882340576 [label=AccumulateGrad]
	139655882327136 -> 139655882331840
	139655883065840 [label="conv_layers.11.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	139655883065840 -> 139655882327136
	139655882327136 [label=AccumulateGrad]
	139655882337984 -> 139655882331840
	139655883066400 [label="conv_layers.11.bias
 (256)" fillcolor=lightblue]
	139655883066400 -> 139655882337984
	139655882337984 [label=AccumulateGrad]
	139655882331984 -> 139655882328720
	139655883066960 [label="conv_layers.12.weight
 (256)" fillcolor=lightblue]
	139655883066960 -> 139655882331984
	139655882331984 [label=AccumulateGrad]
	139655882332368 -> 139655882328720
	139655883067520 [label="conv_layers.12.bias
 (256)" fillcolor=lightblue]
	139655883067520 -> 139655882332368
	139655882332368 [label=AccumulateGrad]
	139655882620496 -> 139655882618768
	139655883066320 [label="conv_layers.15.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	139655883066320 -> 139655882620496
	139655882620496 [label=AccumulateGrad]
	139655882614592 -> 139655882618768
	139655883073120 [label="conv_layers.15.bias
 (512)" fillcolor=lightblue]
	139655883073120 -> 139655882614592
	139655882614592 [label=AccumulateGrad]
	139655882612624 -> 139655882612720
	139655883075520 [label="conv_layers.16.weight
 (512)" fillcolor=lightblue]
	139655883075520 -> 139655882612624
	139655882612624 [label=AccumulateGrad]
	139655882615360 -> 139655882612720
	139655883077280 [label="conv_layers.16.bias
 (512)" fillcolor=lightblue]
	139655883077280 -> 139655882615360
	139655882615360 [label=AccumulateGrad]
	139655882610320 -> 139655882617616
	139655883070560 [label="conv_layers.18.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	139655883070560 -> 139655882610320
	139655882610320 [label=AccumulateGrad]
	139655882619488 -> 139655882617616
	139655883071360 [label="conv_layers.18.bias
 (512)" fillcolor=lightblue]
	139655883071360 -> 139655882619488
	139655882619488 [label=AccumulateGrad]
	139655882616368 -> 139655882607968
	139655883072320 [label="conv_layers.19.weight
 (512)" fillcolor=lightblue]
	139655883072320 -> 139655882616368
	139655882616368 [label=AccumulateGrad]
	139655882613872 -> 139655882607968
	139655883073280 [label="conv_layers.19.bias
 (512)" fillcolor=lightblue]
	139655883073280 -> 139655882613872
	139655882613872 [label=AccumulateGrad]
	139655882620448 -> 139655882620016
	139655883078640 [label="conv_layers.22.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	139655883078640 -> 139655882620448
	139655882620448 [label=AccumulateGrad]
	139655882620064 -> 139655882620016
	139655883079520 [label="conv_layers.22.bias
 (512)" fillcolor=lightblue]
	139655883079520 -> 139655882620064
	139655882620064 [label=AccumulateGrad]
	139655882619200 -> 139655882620688
	139655883066560 [label="conv_layers.23.weight
 (512)" fillcolor=lightblue]
	139655883066560 -> 139655882619200
	139655882619200 [label=AccumulateGrad]
	139655882606768 -> 139655882620688
	139655883066480 [label="conv_layers.23.bias
 (512)" fillcolor=lightblue]
	139655883066480 -> 139655882606768
	139655882606768 [label=AccumulateGrad]
	139655882612576 -> 139655882616704
	139655882612576 [label=TBackward0]
	139655882616608 -> 139655882612576
	139655883075120 [label="linear_layers.0.weight
 (4096, 32768)" fillcolor=lightblue]
	139655883075120 -> 139655882616608
	139655882616608 [label=AccumulateGrad]
	139655882611664 -> 139655882616800
	139655882611664 [label=TBackward0]
	139655882610080 -> 139655882611664
	139655883068640 [label="linear_layers.3.weight
 (2048, 4096)" fillcolor=lightblue]
	139655883068640 -> 139655882610080
	139655882610080 [label=AccumulateGrad]
	139655882617760 -> 139655882618384
	139655882617760 [label=TBackward0]
	139655882606336 -> 139655882617760
	139655883070640 [label="linear_layers.6.weight
 (29, 2048)" fillcolor=lightblue]
	139655883070640 -> 139655882606336
	139655882606336 [label=AccumulateGrad]
	139655882618384 -> 139655882988800
}
