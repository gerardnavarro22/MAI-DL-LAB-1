digraph {
	graph [size="15.75,15.75"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140297113517920 [label="
 (128, 29)" fillcolor=darkolivegreen1]
	140297113263680 [label=AddmmBackward0]
	140297113268048 -> 140297113263680
	140297113253456 [label="fc2.bias
 (29)" fillcolor=lightblue]
	140297113253456 -> 140297113268048
	140297113268048 [label=AccumulateGrad]
	140297113259360 -> 140297113263680
	140297113259360 [label=NativeDropoutBackward0]
	140297113257536 -> 140297113259360
	140297113257536 [label=ReluBackward0]
	140297113265120 -> 140297113257536
	140297113265120 [label=MiopenBatchNormBackward0]
	140297113256864 -> 140297113265120
	140297113256864 [label=AddmmBackward0]
	140297113267520 -> 140297113256864
	140297113254096 [label="fc1.bias
 (512)" fillcolor=lightblue]
	140297113254096 -> 140297113267520
	140297113267520 [label=AccumulateGrad]
	140297113265744 -> 140297113256864
	140297113265744 [label=ViewBackward0]
	140297113256048 -> 140297113265744
	140297113256048 [label=NativeDropoutBackward0]
	140297113257584 -> 140297113256048
	140297113257584 [label=MaxPool2DWithIndicesBackward0]
	140297113256480 -> 140297113257584
	140297113256480 [label=ReluBackward0]
	140297113260944 -> 140297113256480
	140297113260944 [label=ConvolutionBackward0]
	140297113268912 -> 140297113260944
	140297113268912 [label=MaxPool2DWithIndicesBackward0]
	140297113268768 -> 140297113268912
	140297113268768 [label=ReluBackward0]
	140297113266272 -> 140297113268768
	140297113266272 [label=MiopenBatchNormBackward0]
	140297113269296 -> 140297113266272
	140297113269296 [label=ConvolutionBackward0]
	140297113269872 -> 140297113269296
	140297113269872 [label=MaxPool2DWithIndicesBackward0]
	140297113266848 -> 140297113269872
	140297113266848 [label=ReluBackward0]
	140297113268480 -> 140297113266848
	140297113268480 [label=MiopenBatchNormBackward0]
	140297113259120 -> 140297113268480
	140297113259120 [label=ConvolutionBackward0]
	140297113261088 -> 140297113259120
	140297300485328 [label="conv1.weight
 (32, 3, 5, 5)" fillcolor=lightblue]
	140297300485328 -> 140297113261088
	140297113261088 [label=AccumulateGrad]
	140297113267232 -> 140297113259120
	140297297433744 [label="conv1.bias
 (32)" fillcolor=lightblue]
	140297297433744 -> 140297113267232
	140297113267232 [label=AccumulateGrad]
	140297113267808 -> 140297113268480
	140297113062192 [label="batch_norm_conv_1.weight
 (32)" fillcolor=lightblue]
	140297113062192 -> 140297113267808
	140297113267808 [label=AccumulateGrad]
	140297113268000 -> 140297113268480
	140297113062032 [label="batch_norm_conv_1.bias
 (32)" fillcolor=lightblue]
	140297113062032 -> 140297113268000
	140297113268000 [label=AccumulateGrad]
	140297113264496 -> 140297113269296
	140297112942080 [label="conv2.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140297112942080 -> 140297113264496
	140297113264496 [label=AccumulateGrad]
	140297113264016 -> 140297113269296
	140297112941360 [label="conv2.bias
 (64)" fillcolor=lightblue]
	140297112941360 -> 140297113264016
	140297113264016 [label=AccumulateGrad]
	140297113257632 -> 140297113266272
	140297112942400 [label="batch_norm_conv_2.weight
 (64)" fillcolor=lightblue]
	140297112942400 -> 140297113257632
	140297113257632 [label=AccumulateGrad]
	140297113262192 -> 140297113266272
	140297112942160 [label="batch_norm_conv_2.bias
 (64)" fillcolor=lightblue]
	140297112942160 -> 140297113262192
	140297113262192 [label=AccumulateGrad]
	140297113265312 -> 140297113260944
	140297113194864 [label="conv3.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	140297113194864 -> 140297113265312
	140297113265312 [label=AccumulateGrad]
	140297113257872 -> 140297113260944
	140297113202784 [label="conv3.bias
 (128)" fillcolor=lightblue]
	140297113202784 -> 140297113257872
	140297113257872 [label=AccumulateGrad]
	140297113268576 -> 140297113256864
	140297113268576 [label=TBackward0]
	140297113265600 -> 140297113268576
	140297113253376 [label="fc1.weight
 (512, 131072)" fillcolor=lightblue]
	140297113253376 -> 140297113265600
	140297113265600 [label=AccumulateGrad]
	140297113256960 -> 140297113265120
	140297113246416 [label="batch_norm_fcnn.weight
 (512)" fillcolor=lightblue]
	140297113246416 -> 140297113256960
	140297113256960 [label=AccumulateGrad]
	140297113256000 -> 140297113265120
	140297113249616 [label="batch_norm_fcnn.bias
 (512)" fillcolor=lightblue]
	140297113249616 -> 140297113256000
	140297113256000 [label=AccumulateGrad]
	140297113258832 -> 140297113263680
	140297113258832 [label=TBackward0]
	140297113260656 -> 140297113258832
	140297113250016 [label="fc2.weight
 (29, 512)" fillcolor=lightblue]
	140297113250016 -> 140297113260656
	140297113260656 [label=AccumulateGrad]
	140297113263680 -> 140297113517920
}
