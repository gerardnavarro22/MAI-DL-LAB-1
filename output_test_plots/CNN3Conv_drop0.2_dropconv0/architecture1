digraph {
	graph [size="15.45,15.45"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140297113249696 [label="
 (128, 29)" fillcolor=darkolivegreen1]
	140297113262144 [label=AddmmBackward0]
	140297113266080 -> 140297113262144
	140297113255376 [label="fc2.bias
 (29)" fillcolor=lightblue]
	140297113255376 -> 140297113266080
	140297113266080 [label=AccumulateGrad]
	140297113265552 -> 140297113262144
	140297113265552 [label=NativeDropoutBackward0]
	140297113264832 -> 140297113265552
	140297113264832 [label=ReluBackward0]
	140297113264784 -> 140297113264832
	140297113264784 [label=MiopenBatchNormBackward0]
	140297113269584 -> 140297113264784
	140297113269584 [label=AddmmBackward0]
	140297113261520 -> 140297113269584
	140297113253536 [label="fc1.bias
 (512)" fillcolor=lightblue]
	140297113253536 -> 140297113261520
	140297113261520 [label=AccumulateGrad]
	140297113272080 -> 140297113269584
	140297113272080 [label=ViewBackward0]
	140297113263632 -> 140297113272080
	140297113263632 [label=MaxPool2DWithIndicesBackward0]
	140297113257824 -> 140297113263632
	140297113257824 [label=ReluBackward0]
	140297113257296 -> 140297113257824
	140297113257296 [label=ConvolutionBackward0]
	140297113267904 -> 140297113257296
	140297113267904 [label=MaxPool2DWithIndicesBackward0]
	140297113258400 -> 140297113267904
	140297113258400 [label=ReluBackward0]
	140297113261376 -> 140297113258400
	140297113261376 [label=MiopenBatchNormBackward0]
	140297113258448 -> 140297113261376
	140297113258448 [label=ConvolutionBackward0]
	140297113262528 -> 140297113258448
	140297113262528 [label=MaxPool2DWithIndicesBackward0]
	140297113259984 -> 140297113262528
	140297113259984 [label=ReluBackward0]
	140297113271840 -> 140297113259984
	140297113271840 [label=MiopenBatchNormBackward0]
	140297113257104 -> 140297113271840
	140297113257104 [label=ConvolutionBackward0]
	140297112861088 -> 140297113257104
	140297257581152 [label="conv1.weight
 (32, 3, 5, 5)" fillcolor=lightblue]
	140297257581152 -> 140297112861088
	140297112861088 [label=AccumulateGrad]
	140297112854608 -> 140297113257104
	140297286802208 [label="conv1.bias
 (32)" fillcolor=lightblue]
	140297286802208 -> 140297112854608
	140297112854608 [label=AccumulateGrad]
	140297113269728 -> 140297113271840
	140297113194304 [label="batch_norm_conv_1.weight
 (32)" fillcolor=lightblue]
	140297113194304 -> 140297113269728
	140297113269728 [label=AccumulateGrad]
	140297113270784 -> 140297113271840
	140297113202944 [label="batch_norm_conv_1.bias
 (32)" fillcolor=lightblue]
	140297113202944 -> 140297113270784
	140297113270784 [label=AccumulateGrad]
	140297113270832 -> 140297113258448
	140297113063072 [label="conv2.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140297113063072 -> 140297113270832
	140297113270832 [label=AccumulateGrad]
	140297113258880 -> 140297113258448
	140297113062272 [label="conv2.bias
 (64)" fillcolor=lightblue]
	140297113062272 -> 140297113258880
	140297113258880 [label=AccumulateGrad]
	140297113257776 -> 140297113261376
	140297113067312 [label="batch_norm_conv_2.weight
 (64)" fillcolor=lightblue]
	140297113067312 -> 140297113257776
	140297113257776 [label=AccumulateGrad]
	140297113260224 -> 140297113261376
	140297113062112 [label="batch_norm_conv_2.bias
 (64)" fillcolor=lightblue]
	140297113062112 -> 140297113260224
	140297113260224 [label=AccumulateGrad]
	140297113266464 -> 140297113257296
	140297113248656 [label="conv3.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	140297113248656 -> 140297113266464
	140297113266464 [label=AccumulateGrad]
	140297113259456 -> 140297113257296
	140297113248256 [label="conv3.bias
 (128)" fillcolor=lightblue]
	140297113248256 -> 140297113259456
	140297113259456 [label=AccumulateGrad]
	140297113265216 -> 140297113269584
	140297113265216 [label=TBackward0]
	140297113260896 -> 140297113265216
	140297113245536 [label="fc1.weight
 (512, 131072)" fillcolor=lightblue]
	140297113245536 -> 140297113260896
	140297113260896 [label=AccumulateGrad]
	140297113256672 -> 140297113264784
	140297113255616 [label="batch_norm_fcnn.weight
 (512)" fillcolor=lightblue]
	140297113255616 -> 140297113256672
	140297113256672 [label=AccumulateGrad]
	140297113259264 -> 140297113264784
	140297113249776 [label="batch_norm_fcnn.bias
 (512)" fillcolor=lightblue]
	140297113249776 -> 140297113259264
	140297113259264 [label=AccumulateGrad]
	140297113256576 -> 140297113262144
	140297113256576 [label=TBackward0]
	140297113269632 -> 140297113256576
	140297113245936 [label="fc2.weight
 (29, 512)" fillcolor=lightblue]
	140297113245936 -> 140297113269632
	140297113269632 [label=AccumulateGrad]
	140297113262144 -> 140297113249696
}
