digraph {
	graph [size="15.75,15.75"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140297113514640 [label="
 (128, 29)" fillcolor=darkolivegreen1]
	140297112854560 [label=AddmmBackward0]
	140297112853648 -> 140297112854560
	140297113246736 [label="fc2.bias
 (29)" fillcolor=lightblue]
	140297113246736 -> 140297112853648
	140297112853648 [label=AccumulateGrad]
	140297112853504 -> 140297112854560
	140297112853504 [label=NativeDropoutBackward0]
	140297112849232 -> 140297112853504
	140297112849232 [label=ReluBackward0]
	140297112849280 -> 140297112849232
	140297112849280 [label=MiopenBatchNormBackward0]
	140297112858112 -> 140297112849280
	140297112858112 [label=AddmmBackward0]
	140297112854032 -> 140297112858112
	140297113252176 [label="fc1.bias
 (512)" fillcolor=lightblue]
	140297113252176 -> 140297112854032
	140297112854032 [label=AccumulateGrad]
	140297112858256 -> 140297112858112
	140297112858256 [label=ViewBackward0]
	140297112855568 -> 140297112858256
	140297112855568 [label=NativeDropoutBackward0]
	140297112855520 -> 140297112855568
	140297112855520 [label=MaxPool2DWithIndicesBackward0]
	140297112847360 -> 140297112855520
	140297112847360 [label=ReluBackward0]
	140297112852496 -> 140297112847360
	140297112852496 [label=ConvolutionBackward0]
	140297112857296 -> 140297112852496
	140297112857296 [label=MaxPool2DWithIndicesBackward0]
	140297112853360 -> 140297112857296
	140297112853360 [label=ReluBackward0]
	140297113405280 -> 140297112853360
	140297113405280 [label=MiopenBatchNormBackward0]
	140297113405424 -> 140297113405280
	140297113405424 [label=ConvolutionBackward0]
	140297113403456 -> 140297113405424
	140297113403456 [label=MaxPool2DWithIndicesBackward0]
	140297113407872 -> 140297113403456
	140297113407872 [label=ReluBackward0]
	140297113405952 -> 140297113407872
	140297113405952 [label=MiopenBatchNormBackward0]
	140297113418432 -> 140297113405952
	140297113418432 [label=ConvolutionBackward0]
	140297113405232 -> 140297113418432
	140297285464400 [label="conv1.weight
 (32, 3, 5, 5)" fillcolor=lightblue]
	140297285464400 -> 140297113405232
	140297113405232 [label=AccumulateGrad]
	140297113404944 -> 140297113418432
	140297286663952 [label="conv1.bias
 (32)" fillcolor=lightblue]
	140297286663952 -> 140297113404944
	140297113404944 [label=AccumulateGrad]
	140297113406000 -> 140297113405952
	140297112776720 [label="batch_norm_conv_1.weight
 (32)" fillcolor=lightblue]
	140297112776720 -> 140297113406000
	140297113406000 [label=AccumulateGrad]
	140297113403936 -> 140297113405952
	140297286802208 [label="batch_norm_conv_1.bias
 (32)" fillcolor=lightblue]
	140297286802208 -> 140297113403936
	140297113403936 [label=AccumulateGrad]
	140297113403696 -> 140297113405424
	140297113194304 [label="conv2.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140297113194304 -> 140297113403696
	140297113403696 [label=AccumulateGrad]
	140297113407008 -> 140297113405424
	140297113194224 [label="conv2.bias
 (64)" fillcolor=lightblue]
	140297113194224 -> 140297113407008
	140297113407008 [label=AccumulateGrad]
	140297113403648 -> 140297113405280
	140297113203664 [label="batch_norm_conv_2.weight
 (64)" fillcolor=lightblue]
	140297113203664 -> 140297113403648
	140297113403648 [label=AccumulateGrad]
	140297113413152 -> 140297113405280
	140297113202944 [label="batch_norm_conv_2.bias
 (64)" fillcolor=lightblue]
	140297113202944 -> 140297113413152
	140297113413152 [label=AccumulateGrad]
	140297112859648 -> 140297112852496
	140297113245456 [label="conv3.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	140297113245456 -> 140297112859648
	140297112859648 [label=AccumulateGrad]
	140297112853312 -> 140297112852496
	140297113244896 [label="conv3.bias
 (128)" fillcolor=lightblue]
	140297113244896 -> 140297112853312
	140297112853312 [label=AccumulateGrad]
	140297112854320 -> 140297112858112
	140297112854320 [label=TBackward0]
	140297112853168 -> 140297112854320
	140297257581152 [label="fc1.weight
 (512, 131072)" fillcolor=lightblue]
	140297257581152 -> 140297112853168
	140297112853168 [label=AccumulateGrad]
	140297112851440 -> 140297112849280
	140297113255456 [label="batch_norm_fcnn.weight
 (512)" fillcolor=lightblue]
	140297113255456 -> 140297112851440
	140297112851440 [label=AccumulateGrad]
	140297112847072 -> 140297112849280
	140297113245216 [label="batch_norm_fcnn.bias
 (512)" fillcolor=lightblue]
	140297113245216 -> 140297112847072
	140297112847072 [label=AccumulateGrad]
	140297112847168 -> 140297112854560
	140297112847168 [label=TBackward0]
	140297112860032 -> 140297112847168
	140297113250816 [label="fc2.weight
 (29, 512)" fillcolor=lightblue]
	140297113250816 -> 140297112860032
	140297112860032 [label=AccumulateGrad]
	140297112854560 -> 140297113514640
}
