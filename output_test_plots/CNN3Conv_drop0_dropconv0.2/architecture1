digraph {
	graph [size="15.45,15.45"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140297113245456 [label="
 (128, 29)" fillcolor=darkolivegreen1]
	140297113264160 [label=AddmmBackward0]
	140297113262096 -> 140297113264160
	140297113245856 [label="fc2.bias
 (29)" fillcolor=lightblue]
	140297113245856 -> 140297113262096
	140297113262096 [label=AccumulateGrad]
	140297113261232 -> 140297113264160
	140297113261232 [label=ReluBackward0]
	140297113264832 -> 140297113261232
	140297113264832 [label=MiopenBatchNormBackward0]
	140297113272032 -> 140297113264832
	140297113272032 [label=AddmmBackward0]
	140297113266848 -> 140297113272032
	140297113248496 [label="fc1.bias
 (512)" fillcolor=lightblue]
	140297113248496 -> 140297113266848
	140297113266848 [label=AccumulateGrad]
	140297113269488 -> 140297113272032
	140297113269488 [label=ViewBackward0]
	140297113267856 -> 140297113269488
	140297113267856 [label=NativeDropoutBackward0]
	140297113264016 -> 140297113267856
	140297113264016 [label=MaxPool2DWithIndicesBackward0]
	140297113260560 -> 140297113264016
	140297113260560 [label=ReluBackward0]
	140297113267184 -> 140297113260560
	140297113267184 [label=ConvolutionBackward0]
	140297113271648 -> 140297113267184
	140297113271648 [label=MaxPool2DWithIndicesBackward0]
	140297112858112 -> 140297113271648
	140297112858112 [label=ReluBackward0]
	140297112854560 -> 140297112858112
	140297112854560 [label=MiopenBatchNormBackward0]
	140297112859264 -> 140297112854560
	140297112859264 [label=ConvolutionBackward0]
	140297112861664 -> 140297112859264
	140297112861664 [label=MaxPool2DWithIndicesBackward0]
	140297112853360 -> 140297112861664
	140297112853360 [label=ReluBackward0]
	140297112853648 -> 140297112853360
	140297112853648 [label=MiopenBatchNormBackward0]
	140297112861808 -> 140297112853648
	140297112861808 [label=ConvolutionBackward0]
	140297112855088 -> 140297112861808
	140297300485328 [label="conv1.weight
 (32, 3, 5, 5)" fillcolor=lightblue]
	140297300485328 -> 140297112855088
	140297112855088 [label=AccumulateGrad]
	140297112847360 -> 140297112861808
	140297286798368 [label="conv1.bias
 (32)" fillcolor=lightblue]
	140297286798368 -> 140297112847360
	140297112847360 [label=AccumulateGrad]
	140297112847168 -> 140297112853648
	140297285464400 [label="batch_norm_conv_1.weight
 (32)" fillcolor=lightblue]
	140297285464400 -> 140297112847168
	140297112847168 [label=AccumulateGrad]
	140297112858400 -> 140297112853648
	140297297433744 [label="batch_norm_conv_1.bias
 (32)" fillcolor=lightblue]
	140297297433744 -> 140297112858400
	140297112858400 [label=AccumulateGrad]
	140297112854224 -> 140297112859264
	140297187547296 [label="conv2.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140297187547296 -> 140297112854224
	140297112854224 [label=AccumulateGrad]
	140297112857296 -> 140297112859264
	140297113203104 [label="conv2.bias
 (64)" fillcolor=lightblue]
	140297113203104 -> 140297112857296
	140297112857296 [label=AccumulateGrad]
	140297112860032 -> 140297112854560
	140297113194464 [label="batch_norm_conv_2.weight
 (64)" fillcolor=lightblue]
	140297113194464 -> 140297112860032
	140297112860032 [label=AccumulateGrad]
	140297112851056 -> 140297112854560
	140297113194624 [label="batch_norm_conv_2.bias
 (64)" fillcolor=lightblue]
	140297113194624 -> 140297112851056
	140297112851056 [label=AccumulateGrad]
	140297113260128 -> 140297113267184
	140297113255296 [label="conv3.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	140297113255296 -> 140297113260128
	140297113260128 [label=AccumulateGrad]
	140297113261376 -> 140297113267184
	140297113247136 [label="conv3.bias
 (128)" fillcolor=lightblue]
	140297113247136 -> 140297113261376
	140297113261376 [label=AccumulateGrad]
	140297113269392 -> 140297113272032
	140297113269392 [label=TBackward0]
	140297113260704 -> 140297113269392
	140297113249776 [label="fc1.weight
 (512, 131072)" fillcolor=lightblue]
	140297113249776 -> 140297113260704
	140297113260704 [label=AccumulateGrad]
	140297113256720 -> 140297113264832
	140297113249376 [label="batch_norm_fcnn.weight
 (512)" fillcolor=lightblue]
	140297113249376 -> 140297113256720
	140297113256720 [label=AccumulateGrad]
	140297113267664 -> 140297113264832
	140297113255376 [label="batch_norm_fcnn.bias
 (512)" fillcolor=lightblue]
	140297113255376 -> 140297113267664
	140297113267664 [label=AccumulateGrad]
	140297113262048 -> 140297113264160
	140297113262048 [label=TBackward0]
	140297113260032 -> 140297113262048
	140297113249536 [label="fc2.weight
 (29, 512)" fillcolor=lightblue]
	140297113249536 -> 140297113260032
	140297113260032 [label=AccumulateGrad]
	140297113264160 -> 140297113245456
}
