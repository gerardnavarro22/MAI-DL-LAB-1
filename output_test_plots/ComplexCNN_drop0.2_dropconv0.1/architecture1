digraph {
	graph [size="31.95,31.95"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	139655882588000 [label="
 (64, 29)" fillcolor=darkolivegreen1]
	139655882617376 [label=AddmmBackward0]
	139655882616944 -> 139655882617376
	139655882579440 [label="linear_layers.6.bias
 (29)" fillcolor=lightblue]
	139655882579440 -> 139655882616944
	139655882616944 [label=AccumulateGrad]
	139655882616752 -> 139655882617376
	139655882616752 [label=MulBackward0]
	139655882616704 -> 139655882616752
	139655882616704 [label=ReluBackward0]
	139655882616272 -> 139655882616704
	139655882616272 [label=AddmmBackward0]
	139655882615456 -> 139655882616272
	139655882582160 [label="linear_layers.3.bias
 (2048)" fillcolor=lightblue]
	139655882582160 -> 139655882615456
	139655882615456 [label=AccumulateGrad]
	139655882616320 -> 139655882616272
	139655882616320 [label=MulBackward0]
	139655882615648 -> 139655882616320
	139655882615648 [label=ReluBackward0]
	139655882615024 -> 139655882615648
	139655882615024 [label=AddmmBackward0]
	139655882614208 -> 139655882615024
	139655882579760 [label="linear_layers.0.bias
 (4096)" fillcolor=lightblue]
	139655882579760 -> 139655882614208
	139655882614208 [label=AccumulateGrad]
	139655882615072 -> 139655882615024
	139655882615072 [label=ViewBackward0]
	139655882614400 -> 139655882615072
	139655882614400 [label=MulBackward0]
	139655882613776 -> 139655882614400
	139655882613776 [label=MaxPool2DWithIndicesBackward0]
	139655882613056 -> 139655882613776
	139655882613056 [label=ReluBackward0]
	139655882613248 -> 139655882613056
	139655882613248 [label=MiopenBatchNormBackward0]
	139655882612432 -> 139655882613248
	139655882612432 [label=ConvolutionBackward0]
	139655882611808 -> 139655882612432
	139655882611808 [label=MaxPool2DWithIndicesBackward0]
	139655882611184 -> 139655882611808
	139655882611184 [label=ReluBackward0]
	139655882611376 -> 139655882611184
	139655882611376 [label=MiopenBatchNormBackward0]
	139655882606240 -> 139655882611376
	139655882606240 [label=ConvolutionBackward0]
	139655882607296 -> 139655882606240
	139655882607296 [label=ReluBackward0]
	139655882608352 -> 139655882607296
	139655882608352 [label=MiopenBatchNormBackward0]
	139655882608112 -> 139655882608352
	139655882608112 [label=ConvolutionBackward0]
	139655882609072 -> 139655882608112
	139655882609072 [label=MaxPool2DWithIndicesBackward0]
	139655882610272 -> 139655882609072
	139655882610272 [label=ReluBackward0]
	139655882611088 -> 139655882610272
	139655882611088 [label=MiopenBatchNormBackward0]
	139655882620880 -> 139655882611088
	139655882620880 [label=ConvolutionBackward0]
	139655882620160 -> 139655882620880
	139655882620160 [label=ReluBackward0]
	139655882620352 -> 139655882620160
	139655882620352 [label=MiopenBatchNormBackward0]
	139655882619920 -> 139655882620352
	139655882619920 [label=ConvolutionBackward0]
	139655882619632 -> 139655882619920
	139655882619632 [label=MaxPool2DWithIndicesBackward0]
	139655882619296 -> 139655882619632
	139655882619296 [label=ReluBackward0]
	139655882618912 -> 139655882619296
	139655882618912 [label=MiopenBatchNormBackward0]
	139655882619008 -> 139655882618912
	139655882619008 [label=ConvolutionBackward0]
	139655882618672 -> 139655882619008
	139655882618672 [label=MaxPool2DWithIndicesBackward0]
	139655882619248 -> 139655882618672
	139655882619248 [label=ReluBackward0]
	139655882618432 -> 139655882619248
	139655882618432 [label=MiopenBatchNormBackward0]
	139655882618528 -> 139655882618432
	139655882618528 [label=ConvolutionBackward0]
	139655882617712 -> 139655882618528
	139655884338608 [label="conv_layers.0.weight
 (64, 3, 3, 3)" fillcolor=lightblue]
	139655884338608 -> 139655882617712
	139655882617712 [label=AccumulateGrad]
	139655882617664 -> 139655882618528
	139656055655056 [label="conv_layers.0.bias
 (64)" fillcolor=lightblue]
	139656055655056 -> 139655882617664
	139655882617664 [label=AccumulateGrad]
	139655882618480 -> 139655882618432
	139655882375088 [label="conv_layers.1.weight
 (64)" fillcolor=lightblue]
	139655882375088 -> 139655882618480
	139655882618480 [label=AccumulateGrad]
	139655882618288 -> 139655882618432
	139655882373488 [label="conv_layers.1.bias
 (64)" fillcolor=lightblue]
	139655882373488 -> 139655882618288
	139655882618288 [label=AccumulateGrad]
	139655882619152 -> 139655882619008
	139655882360208 [label="conv_layers.4.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	139655882360208 -> 139655882619152
	139655882619152 [label=AccumulateGrad]
	139655882619104 -> 139655882619008
	139655882371888 [label="conv_layers.4.bias
 (128)" fillcolor=lightblue]
	139655882371888 -> 139655882619104
	139655882619104 [label=AccumulateGrad]
	139655882618960 -> 139655882618912
	139655882373968 [label="conv_layers.5.weight
 (128)" fillcolor=lightblue]
	139655882373968 -> 139655882618960
	139655882618960 [label=AccumulateGrad]
	139655882619728 -> 139655882618912
	139656081971360 [label="conv_layers.5.bias
 (128)" fillcolor=lightblue]
	139656081971360 -> 139655882619728
	139655882619728 [label=AccumulateGrad]
	139655882619584 -> 139655882619920
	139655882578080 [label="conv_layers.8.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	139655882578080 -> 139655882619584
	139655882619584 [label=AccumulateGrad]
	139655882619536 -> 139655882619920
	139655882577520 [label="conv_layers.8.bias
 (256)" fillcolor=lightblue]
	139655882577520 -> 139655882619536
	139655882619536 [label=AccumulateGrad]
	139655882620400 -> 139655882620352
	139655882582480 [label="conv_layers.9.weight
 (256)" fillcolor=lightblue]
	139655882582480 -> 139655882620400
	139655882620400 [label=AccumulateGrad]
	139655882620256 -> 139655882620352
	139655882582560 [label="conv_layers.9.bias
 (256)" fillcolor=lightblue]
	139655882582560 -> 139655882620256
	139655882620256 [label=AccumulateGrad]
	139655882620592 -> 139655882620880
	139655882573120 [label="conv_layers.11.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	139655882573120 -> 139655882620592
	139655882620592 [label=AccumulateGrad]
	139655882620544 -> 139655882620880
	139655882577280 [label="conv_layers.11.bias
 (256)" fillcolor=lightblue]
	139655882577280 -> 139655882620544
	139655882620544 [label=AccumulateGrad]
	139655882620784 -> 139655882611088
	139655882578480 [label="conv_layers.12.weight
 (256)" fillcolor=lightblue]
	139655882578480 -> 139655882620784
	139655882620784 [label=AccumulateGrad]
	139655882610512 -> 139655882611088
	139655882579200 [label="conv_layers.12.bias
 (256)" fillcolor=lightblue]
	139655882579200 -> 139655882610512
	139655882610512 [label=AccumulateGrad]
	139655882609360 -> 139655882608112
	139655882574320 [label="conv_layers.15.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	139655882574320 -> 139655882609360
	139655882609360 [label=AccumulateGrad]
	139655882609408 -> 139655882608112
	139655882582240 [label="conv_layers.15.bias
 (512)" fillcolor=lightblue]
	139655882582240 -> 139655882609408
	139655882609408 [label=AccumulateGrad]
	139655882608256 -> 139655882608352
	139655882581760 [label="conv_layers.16.weight
 (512)" fillcolor=lightblue]
	139655882581760 -> 139655882608256
	139655882608256 [label=AccumulateGrad]
	139655882606912 -> 139655882608352
	139655882574960 [label="conv_layers.16.bias
 (512)" fillcolor=lightblue]
	139655882574960 -> 139655882606912
	139655882606912 [label=AccumulateGrad]
	139655882605952 -> 139655882606240
	139655882581520 [label="conv_layers.18.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	139655882581520 -> 139655882605952
	139655882605952 [label=AccumulateGrad]
	139655882605280 -> 139655882606240
	139655882573040 [label="conv_layers.18.bias
 (512)" fillcolor=lightblue]
	139655882573040 -> 139655882605280
	139655882605280 [label=AccumulateGrad]
	139655882611424 -> 139655882611376
	139655882575680 [label="conv_layers.19.weight
 (512)" fillcolor=lightblue]
	139655882575680 -> 139655882611424
	139655882611424 [label=AccumulateGrad]
	139655882612000 -> 139655882611376
	139655882579120 [label="conv_layers.19.bias
 (512)" fillcolor=lightblue]
	139655882579120 -> 139655882612000
	139655882612000 [label=AccumulateGrad]
	139655882612672 -> 139655882612432
	139655882580880 [label="conv_layers.22.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	139655882580880 -> 139655882612672
	139655882612672 [label=AccumulateGrad]
	139655882612624 -> 139655882612432
	139655882573360 [label="conv_layers.22.bias
 (512)" fillcolor=lightblue]
	139655882573360 -> 139655882612624
	139655882612624 [label=AccumulateGrad]
	139655882613296 -> 139655882613248
	139655882576640 [label="conv_layers.23.weight
 (512)" fillcolor=lightblue]
	139655882576640 -> 139655882613296
	139655882613296 [label=AccumulateGrad]
	139655882613584 -> 139655882613248
	139655882572480 [label="conv_layers.23.bias
 (512)" fillcolor=lightblue]
	139655882572480 -> 139655882613584
	139655882613584 [label=AccumulateGrad]
	139655882614832 -> 139655882615024
	139655882614832 [label=TBackward0]
	139655882613824 -> 139655882614832
	139655882581600 [label="linear_layers.0.weight
 (4096, 32768)" fillcolor=lightblue]
	139655882581600 -> 139655882613824
	139655882613824 [label=AccumulateGrad]
	139655882617568 -> 139655882616272
	139655882617568 [label=TBackward0]
	139655882614256 -> 139655882617568
	139655882574400 [label="linear_layers.3.weight
 (2048, 4096)" fillcolor=lightblue]
	139655882574400 -> 139655882614256
	139655882614256 [label=AccumulateGrad]
	139655882616896 -> 139655882617376
	139655882616896 [label=TBackward0]
	139655882615504 -> 139655882616896
	139655882582080 [label="linear_layers.6.weight
 (29, 2048)" fillcolor=lightblue]
	139655882582080 -> 139655882615504
	139655882615504 [label=AccumulateGrad]
	139655882617376 -> 139655882588000
}
