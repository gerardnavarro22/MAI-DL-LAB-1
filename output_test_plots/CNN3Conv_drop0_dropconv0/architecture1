digraph {
	graph [size="15.149999999999999,15.149999999999999"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140297113510480 [label="
 (128, 29)" fillcolor=darkolivegreen1]
	140297113261856 [label=AddmmBackward0]
	140297113267280 -> 140297113261856
	140297113253776 [label="fc2.bias
 (29)" fillcolor=lightblue]
	140297113253776 -> 140297113267280
	140297113267280 [label=AccumulateGrad]
	140297113260560 -> 140297113261856
	140297113260560 [label=ReluBackward0]
	140297113260896 -> 140297113260560
	140297113260896 [label=MiopenBatchNormBackward0]
	140297113257344 -> 140297113260896
	140297113257344 [label=AddmmBackward0]
	140297113270928 -> 140297113257344
	140297113253216 [label="fc1.bias
 (512)" fillcolor=lightblue]
	140297113253216 -> 140297113270928
	140297113270928 [label=AccumulateGrad]
	140297113268912 -> 140297113257344
	140297113268912 [label=ViewBackward0]
	140297113260704 -> 140297113268912
	140297113260704 [label=MaxPool2DWithIndicesBackward0]
	140297113264016 -> 140297113260704
	140297113264016 [label=ReluBackward0]
	140297113268528 -> 140297113264016
	140297113268528 [label=ConvolutionBackward0]
	140297113269392 -> 140297113268528
	140297113269392 [label=MaxPool2DWithIndicesBackward0]
	140297113259984 -> 140297113269392
	140297113259984 [label=ReluBackward0]
	140297113257152 -> 140297113259984
	140297113257152 [label=MiopenBatchNormBackward0]
	140297113264160 -> 140297113257152
	140297113264160 [label=ConvolutionBackward0]
	140297113261376 -> 140297113264160
	140297113261376 [label=MaxPool2DWithIndicesBackward0]
	140297113262096 -> 140297113261376
	140297113262096 [label=ReluBackward0]
	140297113265456 -> 140297113262096
	140297113265456 [label=MiopenBatchNormBackward0]
	140297113257248 -> 140297113265456
	140297113257248 [label=ConvolutionBackward0]
	140297113256720 -> 140297113257248
	140297303136896 [label="conv1.weight
 (32, 3, 5, 5)" fillcolor=lightblue]
	140297303136896 -> 140297113256720
	140297113256720 [label=AccumulateGrad]
	140297113269776 -> 140297113257248
	140297193023072 [label="conv1.bias
 (32)" fillcolor=lightblue]
	140297193023072 -> 140297113269776
	140297113269776 [label=AccumulateGrad]
	140297113269824 -> 140297113265456
	140297113067312 [label="batch_norm_conv_1.weight
 (32)" fillcolor=lightblue]
	140297113067312 -> 140297113269824
	140297113269824 [label=AccumulateGrad]
	140297113271360 -> 140297113265456
	140297113063152 [label="batch_norm_conv_1.bias
 (32)" fillcolor=lightblue]
	140297113063152 -> 140297113271360
	140297113271360 [label=AccumulateGrad]
	140297113267184 -> 140297113264160
	140297113062112 [label="conv2.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140297113062112 -> 140297113267184
	140297113267184 [label=AccumulateGrad]
	140297113269488 -> 140297113264160
	140297113203024 [label="conv2.bias
 (64)" fillcolor=lightblue]
	140297113203024 -> 140297113269488
	140297113269488 [label=AccumulateGrad]
	140297113260800 -> 140297113257152
	140297113203824 [label="batch_norm_conv_2.weight
 (64)" fillcolor=lightblue]
	140297113203824 -> 140297113260800
	140297113260800 [label=AccumulateGrad]
	140297113259456 -> 140297113257152
	140297113203584 [label="batch_norm_conv_2.bias
 (64)" fillcolor=lightblue]
	140297113203584 -> 140297113259456
	140297113259456 [label=AccumulateGrad]
	140297113264832 -> 140297113268528
	140297295350656 [label="conv3.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	140297295350656 -> 140297113264832
	140297113264832 [label=AccumulateGrad]
	140297113260368 -> 140297113268528
	140297113247696 [label="conv3.bias
 (128)" fillcolor=lightblue]
	140297113247696 -> 140297113260368
	140297113260368 [label=AccumulateGrad]
	140297113271312 -> 140297113257344
	140297113271312 [label=TBackward0]
	140297113261280 -> 140297113271312
	140297113254256 [label="fc1.weight
 (512, 131072)" fillcolor=lightblue]
	140297113254256 -> 140297113261280
	140297113261280 [label=AccumulateGrad]
	140297113257440 -> 140297113260896
	140297113247616 [label="batch_norm_fcnn.weight
 (512)" fillcolor=lightblue]
	140297113247616 -> 140297113257440
	140297113257440 [label=AccumulateGrad]
	140297113256288 -> 140297113260896
	140297113251456 [label="batch_norm_fcnn.bias
 (512)" fillcolor=lightblue]
	140297113251456 -> 140297113256288
	140297113256288 [label=AccumulateGrad]
	140297113260128 -> 140297113261856
	140297113260128 [label=TBackward0]
	140297113266656 -> 140297113260128
	140297113254016 [label="fc2.weight
 (29, 512)" fillcolor=lightblue]
	140297113254016 -> 140297113266656
	140297113266656 [label=AccumulateGrad]
	140297113261856 -> 140297113510480
}
